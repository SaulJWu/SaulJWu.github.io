## 环境准备

## 安装路径：

D:\Linux\test

### 前置要求

准备一台机子，安装好vagrant和VirtualBox

操作系统：Centos7.x-85 x64

硬件配置：

- CPU 2GB以上
- 内存 4G以上
- 硬盘30G以上
- 集群中所有机器之间网络互通
- 可以访问外网，需要拉取镜像
- 进制swap分区





### VirtualBox配置

#### 指定默认虚拟机位置

![image-20210630115118341](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630115118.png)

#### 创建网卡

![image-20210630115233574](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630115233.png)

![image-20210630115248908](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630115248.png)

#### 主机网络管理

能够相互ping通

![image-20210630115321415](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630115321.png)

### VagrantFile准备

~~~bash
Vagrant.configure("2") do |config|
	(1..3).each do |i|
		config.vm.define "k8s-node#{i}" do |node|
			# 设置虚拟机的Box
			node.vm.box = "centos/7"

			# 设置虚拟机的主机名
			node.vm.hostname="k8s-node#{i}"

			# 设置虚拟机的IP
			node.vm.network "private_network", ip: "192.168.56.#{100+i}", netmask: "255.255.255.0"

			# 设置主机与虚拟机的共享目录
			# node.vm.synced_folder "~/Documents/vagrant/share", "/home/vagrant/share"

			# VirtaulBox相关配置
			node.vm.provider "virtualbox" do |v|
				# 设置虚拟机的名称
				v.name = "k8s-node#{i}"
				# 设置虚拟机的内存大小
				#v.memory = 8192
				# 设置虚拟机的CPU个数
				#v.cpus = 4
			end
		end
	end
end
~~~



### 初始化虚拟机

#### 创建虚拟机

```bash
vagrant up
```

接下来慢慢下载虚拟机，慢慢创建三个节点，可以观察virtualBox

![image-20210630115558352](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630115558.png)

三个节点正常运行

#### 设置虚拟机可以通过ssh密码访问

```bash
vagrant ssh k8s-node1
su root
# 密码也是vagrant
vi /etc/ssh/sshd_config
```

![image-20210630120013741](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210630120013.png)

改为`yes`后，按`ESC`，然后输入`:wq`保存

```bash
# 重启sshd
service sshd restart
```

重启sshd，如果忘记了，重启虚拟机就可以了

因为我vagrant是从100+i开始，所以我k8s第一个节点的ip为101

所以shell连接`192.168.56.101`就可以了，然后把另外2个节点都改好可以通过shell连接。

#### 虚拟机ip shell连接

| 名字      | ip（三个端口都是22） | 账号密码     |
| --------- | -------------------- | ------------ |
| k8s-node1 | 192.168.56.101       | root/vagrant |
| k8s-node2 | 192.168.56.102       | root/vagrant |
| k8s-node3 | 192.168.56.103       | root/vagrant |

重启sshd后，可以试试shell能否用密码链接



# todo(重新配网络)

## 时间同步，要保证所有机子的时间是一致的

```bash
yum install ntp
ntpdate cn.pool.ntp.org
ntpdate 0.centos.pool.ntp.org
ln -s ../usr/share/zoneinfo/Asia/Shanghai /etc/localtime
date
clock -w
clock --hctosys
```

#### 关闭防火墙

所有k8s命令行输入   

```
systemctl stop firewalld

systemctl disable firewalld
```



#### 关闭selinux

所有k8s命令行输入   

```
sed -i 's/enforcing/disabled/' /etc/selinux/config

cat /etc/selinux/config

 setenforce 0


```

![image-20210709112137444](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709112137444.png)

#### 关闭内存交换

```
swapoff -a

sed -ri 's/.*swap.*/#&/' /etc/fstab
```



![image-20210709114221247](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709114221247.png)

#### 配置各个IP地址

```
10.0.2.6 k8s-node1

10.0.2.5 k8s-node2

10.0.2.15 k8s-node3
```

(注意要看各个的ip，不是随便取的 )![image-20210709115001333](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709115001333.png)

```
vi /etc/hosts
```

![image-20210709115508260](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709115508260.png)





```
cat > /etc/sysctl.d/k8s.conf << EOF

> net.bridge.bridge-nf-call-ip6tables = 1
> net.bridge.bridge-nf-call-iptables = 1
> EOF

 sysctl --system
```

![image-20210709120011315](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709120011315.png)

#### 卸载 docker

> ```
> sudo yum remove docker \
> 
> > docker-client \
> > docker-client-latest \
> > docker-common \
> > docker-latest \
> > docker-latest-logrotate \
> > docker-logrotate \
> > docker-engine
> ```
>
> ![image-20210709141049322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709141049322.png)

#### 安装docker-ce

> ```
> sudo yum install -y yum-utils \
> 
> > device-mapper-persistent-data \
> > lvm2
> 
>  sudo yum-config-manager \
> 
> > --add-repo \
> > https://download.docker.com/linux/centos/docker-ce.repo
> ```
>
> 

#### 安装docker

```
sudo yum install -y docker-ce docker-ce-di containerd.io


```

配置docker加速

```
sudo mkdir -p /etc/docker

sudo tee /etc/docker/daemon.json <<- 'EOF'

> {
> "registry-mirrors":["https://82m9ar63.mirror.aliyuncs.com"]
> }
> EOF

sudo systemctl daemon-reload

sudo systemctl restart docker
```

启动docker

```
systemctl enable docker
```



#### 安装kubeadm kubelet kubectl

> ```
> cat > /etc/yum.repos.d/kubernetes.repo << EOF
> 
> > [kubernetes]
> > name=Kubernetes
> > baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
> > enabled=1
> > gpgcheck=0
> > repo_gpgcheck=0
> > gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
> > https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
> > EOF
> ```
>
> 

启动

```
systemctl enable kubelet

systemctl start kubelet
```



### 配置master

下载镜像

![image-20210709154229763](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709154229763.png)

![image-20210709154330258](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709154330258.png)

```
sed -i "s/\r//" master_images.sh 

./master_images.sh 
```

```bash
kubeadm init \
 --apiserver-advertise-address=10.0.2.6 \
 --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \
 --kubernetes-version v1.17.3 \
 --service-cidr=10.96.0.0/16 \
 --pod-network-cidr=10.244.0.0/16

```

如果上面执行失败，请设置虚拟机为2核2g并重启kubeadm  (kubeadm reset)

![image-20210709164322330](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709164322330.png)![image-20210709164515609](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709164515609.png)

安装kube-flannel

```
kubectl apply -f kube-flannel.yml
```

yml源码

```
---
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: psp.flannel.unprivileged
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default
    seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default
    apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
    apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
spec:
  privileged: false
  volumes:
    - configMap
    - secret
    - emptyDir
    - hostPath
  allowedHostPaths:
    - pathPrefix: "/etc/cni/net.d"
    - pathPrefix: "/etc/kube-flannel"
    - pathPrefix: "/run/flannel"
  readOnlyRootFilesystem: false
  # Users and groups
  runAsUser:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  fsGroup:
    rule: RunAsAny
  # Privilege Escalation
  allowPrivilegeEscalation: false
  defaultAllowPrivilegeEscalation: false
  # Capabilities
  allowedCapabilities: ['NET_ADMIN']
  defaultAddCapabilities: []
  requiredDropCapabilities: []
  # Host namespaces
  hostPID: false
  hostIPC: false
  hostNetwork: true
  hostPorts:
  - min: 0
    max: 65535
  # SELinux
  seLinux:
    # SELinux is unused in CaaSP
    rule: 'RunAsAny'
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
rules:
  - apiGroups: ['extensions']
    resources: ['podsecuritypolicies']
    verbs: ['use']
    resourceNames: ['psp.flannel.unprivileged']
  - apiGroups:
      - ""
    resources:
      - pods
    verbs:
      - get
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - list
      - watch
  - apiGroups:
      - ""
    resources:
      - nodes/status
    verbs:
      - patch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: flannel
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: flannel
subjects:
- kind: ServiceAccount
  name: flannel
  namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: flannel
  namespace: kube-system
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: kube-flannel-cfg
  namespace: kube-system
  labels:
    tier: node
    app: flannel
data:
  cni-conf.json: |
    {
      "name": "cbr0",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "flannel",
          "delegate": {
            "hairpinMode": true,
            "isDefaultGateway": true
          }
        },
        {
          "type": "portmap",
          "capabilities": {
            "portMappings": true
          }
        }
      ]
    }
  net-conf.json: |
    {
      "Network": "10.244.0.0/16",
      "Backend": {
        "Type": "vxlan"
      }
    }
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-amd64
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - amd64
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-amd64
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-amd64
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
            add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-arm64
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - arm64
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-arm64
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-arm64
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-arm
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - arm
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-arm
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-arm
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-ppc64le
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - ppc64le
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-ppc64le
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-ppc64le
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kube-flannel-ds-s390x
  namespace: kube-system
  labels:
    tier: node
    app: flannel
spec:
  selector:
    matchLabels:
      app: flannel
  template:
    metadata:
      labels:
        tier: node
        app: flannel
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: beta.kubernetes.io/os
                    operator: In
                    values:
                      - linux
                  - key: beta.kubernetes.io/arch
                    operator: In
                    values:
                      - s390x
      hostNetwork: true
      tolerations:
      - operator: Exists
        effect: NoSchedule
      serviceAccountName: flannel
      initContainers:
      - name: install-cni
        image: quay.io/coreos/flannel:v0.11.0-s390x
        command:
        - cp
        args:
        - -f
        - /etc/kube-flannel/cni-conf.json
        - /etc/cni/net.d/10-flannel.conflist
        volumeMounts:
        - name: cni
          mountPath: /etc/cni/net.d
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-s390x
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        resources:
          requests:
            cpu: "100m"
            memory: "50Mi"
          limits:
            cpu: "100m"
            memory: "50Mi"
        securityContext:
          privileged: false
          capabilities:
             add: ["NET_ADMIN"]
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        volumeMounts:
        - name: run
          mountPath: /run/flannel
        - name: flannel-cfg
          mountPath: /etc/kube-flannel/
      volumes:
        - name: run
          hostPath:
            path: /run/flannel
        - name: cni
          hostPath:
            path: /etc/cni/net.d
        - name: flannel-cfg
          configMap:
            name: kube-flannel-cfg


```



![image-20210709170334588](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709170334588.png)

在k8s-node2 k8s-node3加入主里

```
kubeadm join 10.0.2.6:6443 --token ieq2ad.9tnshj8sten3a6tz \
    --discovery-token-ca-cert-hash sha256:c6d1ac1a49f3d2d466c7d8e48502047541f81a32e70742fc10cc7ea9f9d7c057
```

注意：上面代码是node1里的

![image-20210709174240075](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709174240075.png)

![image-20210709174413898](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210709174413898.png)

#### 安装kubeSphere

视频教程网站访问不到的去github下载压缩包

```
https://github.com/helm/helm/releases
```

![image-20210710141918286](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210710141918286.png)

解压放到bin目录

注意3以上版本没有init tiller

```
tar -zxvf helm-v2.16.12-linux-amd64.tar.gz 
mv linux-amd64/helm /usr/local/bin/helm
helm help
```

![image-20210710115640235](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210710115640235.png)

创建helm-rbac.yaml文件并应用

```
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
```





## 帐号

```bash
kubectl patch users admin -p '{"spec":{"password":"YuanBang666"}}' --type='merge' && kubectl annotate users "admin" iam.kubesphere.io/password-encrypted- 
```



admin

密码（默认密码：P@88w0rd）

YuanBang666

![image-20210710180315676](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20210710180315676.png)

