## 一、KubeSphere简介

KubeSphere 是在 Kubernetes 之上构建的以应用为中心的多租户容器管理平台，支持部署和运行在任何基础设施之上，提供简单易用的操作界面以及向导式操作方式，在降低用户使用容器调度平台学习成本的同时，极大减轻开发、测试、运维的日常工作的复杂度，旨在解决 Kubernetes 本身存在的存储、网络、安全和易用性等痛点。帮助企业轻松应对敏捷开发、自动化运维、应用快速交付、微服务治理、多租户管理、监控日志告警、服务与网络管理、镜像仓库等业务场景。

我们刚开始学习使用k8s，一般使用的是docker+kubeadm部署k8s集群，然后再部署周边的各组件，例如harbor，gitlab，jenkins，监控与告警（grafana，prometheus）,日志（elk，efk），ingress，helm、主机资源管理等各种组件，并让这些组件进行协同工作。而通过Kubesphere，我们可以简化这些流程，Kubesphere把上述的大部分组件进行了整合，安装了Kubesphere就是安装并整合了这些组件。

简单来说，就是我们可以使用Kubesphere来管理k8s及其相关的组件，降低部署、学习成本，提供了一个完整的k8s集群方案。

下面介绍具体的安装流程，主要参考：https://v2-1.docs.kubesphere.io/docs/zh-CN/

## 二、安装

### 1、安装helm（master节点执行）

Helm是 Kubemeters 的包管理器。包管理器类似于我们在 Ubuntu中使用的apt, CentOS 中使用的 yum或者 Python中的 pip一样，能快速查找、下载和安装软件包。Helm是客户端组件 helm 和服务端组件 Tiller 组成，能够将一组 k8s 资源打包统一管理，是查找、共享和使用为 kubernetes 构建的软件的最佳方式。

#### 1)、下载

```bash
curl -L https://git.io/get_helm.sh | bash

# 如果下载不了，请使用我上传到阿里云OSS的文件
# https://digtime-k8s.oss-cn-heyuan.aliyuncs.com/k8s/get_helm.sh
curl -L https://digtime-k8s.oss-cn-heyuan.aliyuncs.com/k8s/get_helm.sh | bash
```

墙的原因，上传我们给定的 get_helm.sh, chmod 700, 然后 `./get_helm.sh`,可能有文件格式兼容问题，用vi打开该 sh 文件，输入：

或者手动安装方式：

```bash
$ 下载 Helm 二进制文件
# $ wget https://storage.googleapis.com/kubernetes-helm/helm-v2.16.12-linux-amd64.tar.gz
 # 国内源
$ wget https://digtime-k8s.oss-cn-heyuan.aliyuncs.com/k8s/helm-v2.16.12-linux-amd64.tar.gz

$ 解压缩
$ tar -zxvf helm-v2.16.12-linux-amd64.tar.gz

$ 复制 helm 二进制 到bin目录下
$ cp linux-amd64/helm /usr/local/bin/
```

#### 2)、验证版本

```bash
helm version
```

#### 3)、创建权限(master执行)

创建 `helm-rbac.yaml`，写入如下内容：

```yml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
```

应用配置：

```bash
kubectl apply -f helm-rbac.yaml
```

### 2、安装 Tiller(master执行)

#### 1)、安装：

```bash
helm init
```

这个地方默认使用 “[https://kubernetes-charts.storage.googleapis.com](https://kubernetes-charts.storage.googleapis.com/)” 作为缺省的 stable repository 的地址，但由于国内有一张无形的墙的存在，googleapis.com 是不能访问的。可以使用阿里云的源来配置：

```bash
helm init --upgrade -i registry.cn-hangzhou.aliyuncs.com/google_containers/tiller:v2.16.12  --stable-repo-url https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
```

执行上面命令后，可以通过 `kubectl get po -n kube-system` 来查看 tiller 的安装情况。

查看 Tiller 是否安装成功

```bash
[root@k8s-node2 bin]# helm version 
Client: &version.Version{SemVer:"v2.16.12", GitCommit:"47f0b88409e71fd9ca272abc7cd762a56a1c613e", GitTreeState:"clean"}
Server: &version.Version{SemVer:"v2.16.12", GitCommit:"47f0b88409e71fd9ca272abc7cd762a56a1c613e", GitTreeState:"clean"}
[root@k8s-node2 bin]# 
```

安装成功后，即可使用 `helm install xxx` 来安装 `helm` 应用。如果需要删除 Tiller，可以通过 `kubectl delete deployment tiller-deploy --namespace kube-system` 来删除 Tiller 的 deployment 或者使用 `helm reset`来删除。

#### 2)、初始化

```php
helm init --service-account=tiller  --tiller-image=sapcc/tiller:v2.16.12 --history-max 300 
--tiller-image #指定镜像，否则会被墙
```

等待节点上部署的 tiller 完成即可。

#### 3)、测试

```php
helm install stable/nginx-ingress --name nginx-ingress
```

#### 4)、获取节点信息

```php
[root@k8s-node2 ~]# kubectl get node -o wide
NAME        STATUS   ROLES    AGE     VERSION   INTERNAL-IP   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME
k8s-node1   Ready    <none>   4d      v1.17.3   10.0.2.6      <none>        CentOS Linux 7 (Core)   3.10.0-957.12.2.el7.x86_64   docker://19.3.13
k8s-node2   Ready    master   4d15h   v1.17.3   10.0.2.4      <none>        CentOS Linux 7 (Core)   3.10.0-957.12.2.el7.x86_64   docker://19.3.13
k8s-node3   Ready    <none>   4d1h    v1.17.3   10.0.2.5      <none>        CentOS Linux 7 (Core)   3.10.0-957.12.2.el7.x86_64   docker://19.3.13
[root@k8s-node2 ~]# 
```

### 3、安装 OpenEBS 创建 LocalPV 存储类型

[安装 OpenEBS 创建 LocalPV 存储类型](https://v2-1.docs.kubesphere.io/docs/zh-CN/appendix/install-openebs/)

#### 1)、查看master是否有污点

```php
[root@k8s-node2 vagrant]# kubectl describe node k8s-node2 | grep Taint
Taints:             node-role.kubernetes.io/master:NoSchedule
```

#### 2)、去掉去掉 master 节点的 Taint：

```php
[root@k8s-node2 vagrant]# kubectl taint nodes k8s-node2 node-role.kubernetes.io/master:NoSchedule-
node/k8s-node2 untainted
```

#### 3)、安装 OpenEBS

创建 OpenEBS 的 namespace，OpenEBS 相关资源将创建在这个 namespace 下：

```php
kubectl create ns openebs
```

安装 OpenEBS，以下列出两种方法，可参考其中任意一种进行创建：

```php
helm install --namespace openebs --name openebs stable/openebs --version 1.5.0
```

在执行上边的语句时，出现了权限的问题：

```php
[root@k8s-node2 k8s]# helm install --namespace openebs --name openebs stable/openebs --version 1.5.0
Error: release openebs failed: namespaces "openebs" is forbidden: User "system:serviceaccount:kube-system:default" cannot get resource "namespaces" in API group "" in the namespace "openebs"
```

参考该篇文章： https://github.com/helm/helm/issues/3130 ，

```php
[root@k8s-node2 k8s]# kubectl --namespace kube-system create serviceaccount tiller
Error from server (AlreadyExists): serviceaccounts "tiller" already exists
[root@k8s-node2 k8s]# kubectl create clusterrolebinding tiller-cluster-rule \
 --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
clusterrolebinding.rbac.authorization.k8s.io/tiller-cluster-rule created
[root@k8s-node2 k8s]# kubectl --namespace kube-system patch deploy tiller-deploy \
  -p '{"spec":{"template":{"spec":{"serviceAccount":"tiller"}}}}' 
deployment.apps/tiller-deploy patched

[root@k8s-node2 k8s]# helm list
[root@k8s-node2 k8s]# helm repo update
Hang tight while we grab the latest from your chart repositories...
```

安装 OpenEBS 后将自动创建 4 个 StorageClass，查看创建的 StorageClass：

```php
$ kubectl get sc
NAME                        PROVISIONER                                                AGE
openebs-device              openebs.io/local                                           10h
openebs-hostpath            openebs.io/local                                           10h
openebs-jiva-default        openebs.io/provisioner-iscsi                               10h
openebs-snapshot-promoter   volumesnapshot.external-storage.k8s.io/snapshot-promoter   10h
```

如下将 `openebs-hostpath` 设置为 默认的 StorageClass：

```php
$ kubectl patch storageclass openebs-hostpath -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'
storageclass.storage.k8s.io/openebs-hostpath patched
```

至此，OpenEBS 的 LocalPV 已作为默认的存储类型创建成功。可以通过命令 `kubectl get pod -n openebs`来查看 OpenEBS 相关 Pod 的状态，若 Pod 的状态都是 running，则说明存储安装成功。

![file](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210809105612.png)

通过上边的命令查看，由于国内墙的原因，镜像拉取失败，所以采用kubectl 安装方式：

通过 kubectl 命令安装：

```php
kubectl apply -f https://openebs.github.io/charts/openebs-operator-1.5.0.yaml
```

k8s在使用编排（manifest）工具进行yaml文件启动pod时，会遇到官方所给例子中spec.containers.image包含：

```php
quay.io/coreos/example_
gcr.io/google_containers/example_
```

也就是说，从quay.io和gcr.io进行镜像拉取，我们知道，国内访问外网是被屏蔽了的。可以将其替换为 quay-mirror.qiniu.com 和 registry.aliyuncs.com

例如
下拉镜像：quay.io/coreos/flannel:v0.10.0-s390x
如果拉取较慢，可以改为：quay-mirror.qiniu.com/coreos/flannel:v0.10.0-s390x

下拉镜像：gcr.io/google_containers/kube-proxy
可以改为： registry.aliyuncs.com/google_containers/kube-proxy

将 `openebs-operator-1.5.0.yaml` 文件中的 `quay.io` 改为 `quay-mirror.qiniu.com` 即可下载镜像。