文档参考：[多节点安装 (kubesphere.com.cn)](https://kubesphere.com.cn/docs/installing-on-linux/introduction/multioverview/)

## 1、准备环境

### 确保三台机能ping通

```bash
ping 10.0.2.9
ping 10.0.2.7
ping 10.0.2.8
```



### 确保三个节点都能相互访问

```bash
ssh 10.0.2.9
ssh 10.0.2.7
ssh 10.0.2.8
```



### 安装工具

```bash
# docker这里就不展开说明
docker -v

# socat
yum -y install socat

# conntrack
yum -y install conntrack
```

### 时间同步

```bash
# 时间同步
timedatectl
```



![image-20210812192209092](https://gitee.com/SaulJWu/blog-images/raw/master/images/20210812192216.png)

发现时间跟我们的不一样

```bash
# 切换到上海
timedatectl set-timezone Asia/Shanghai
```

再次查看，发现本地时间已经切换到中国时间，并且三台机器的时间都是一样的。

```bash
yum -y install chrony
```

安装完后，查看一下时间同步服务器列表

```bash
chronyc -n sources -v
```

查看本机时间统统同步状态

```bash
chronyc tracking
```

核查本地时间

```bash
timedatectl status
```

可以看到三个机器是一样的了，如果要用到集群中某个机器为准点为时间机器，需要修改配置



## 2、下载pubkey

**三台机器都能相互ping通后，接下来在master操作**

```bash
curl -sfL https://get-kk.kubesphere.io | VERSION=v1.1.1 sh -
```

返回：

> Downloading kubekey v1.1.1 from https://github.com/kubesphere/kubekey/releases/download/v1.1.1/kubekey-v1.1.1-linux-amd64.tar.gz ...
>
>
> Kubekey v1.1.1 Download Complete!

为 `kk` 添加可执行权限：

```
chmod +x kk
```



## 3、创建集群

### 3.1、创建示例配件文件

```bash
./kk create config --with-kubernetes v1.19.8 --with-kubesphere v3.1.1
```

会在当前文件夹生成`config.sample.yaml`

### 3.2、配置文件

```bash
vi config-sample.yaml
```

```bash
apiVersion: kubekey.kubesphere.io/v1alpha1
kind: Cluster
metadata:
  name: sample
spec:
  hosts:
  - {name: k8s-node1, address: 10.0.2.9, internalAddress: 192.168.56.101, user: root, password: vagrant}
  - {name: k8s-node2, address: 10.0.2.7, internalAddress: 192.168.56.102, user: root, password: vagrant}
  - {name: k8s-node3, address: 10.0.2.8, internalAddress: 192.168.56.103, user: root, password: vagrant}
  roleGroups:
    etcd:
    - k8s-node1
    master: 
    - k8s-node1
    worker:
    - k8s-node1
    - k8s-node2
    - k8s-node3
  controlPlaneEndpoint:
    domain: lb.kubesphere.local
    address: ""
    port: 6443
  kubernetes:
    version: v1.19.8
    imageRepo: kubesphere
    clusterName: cluster.local
  network:
    plugin: calico
    kubePodsCIDR: 10.233.64.0/18
    kubeServiceCIDR: 10.233.0.0/18
  registry:
    registryMirrors: []
    insecureRegistries: []
  addons: []


---
apiVersion: installer.kubesphere.io/v1alpha1
kind: ClusterConfiguration
metadata:
  name: ks-installer
  namespace: kubesphere-system
  labels:
    version: v3.1.1
spec:
  persistence:
    storageClass: ""       
  authentication:
    jwtSecret: ""
  zone: ""
  local_registry: ""        
  etcd:
    monitoring: false      
    endpointIps: localhost  
    port: 2379             
    tlsEnable: true
  common:
    redis:
      enabled: false
    redisVolumSize: 2Gi 
    openldap:
      enabled: false
    openldapVolumeSize: 2Gi  
    minioVolumeSize: 20Gi
    monitoring:
      endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090
    es:  
      elasticsearchMasterVolumeSize: 4Gi   
      elasticsearchDataVolumeSize: 20Gi   
      logMaxAge: 7          
      elkPrefix: logstash
      basicAuth:
        enabled: false
        username: ""
        password: ""
      externalElasticsearchUrl: ""
      externalElasticsearchPort: ""  
  console:
    enableMultiLogin: true 
    port: 30880
  alerting:       
    enabled: false
    # thanosruler:
    #   replicas: 1
    #   resources: {}
  auditing:    
    enabled: false
  devops:           
    enabled: false
    jenkinsMemoryLim: 2Gi     
    jenkinsMemoryReq: 1500Mi 
    jenkinsVolumeSize: 8Gi   
    jenkinsJavaOpts_Xms: 512m  
    jenkinsJavaOpts_Xmx: 512m
    jenkinsJavaOpts_MaxRAM: 2g
  events:          
    enabled: false
    ruler:
      enabled: true
      replicas: 2
  logging:         
    enabled: false
    logsidecar:
      enabled: true
      replicas: 2
  metrics_server:             
    enabled: false
  monitoring:
    storageClass: ""
    prometheusMemoryRequest: 400Mi  
    prometheusVolumeSize: 20Gi  
  multicluster:
    clusterRole: none 
  network:
    networkpolicy:
      enabled: false
    ippool:
      type: none
    topology:
      type: none
  openpitrix:
    store:
      enabled: false
  servicemesh:    
    enabled: false  
  kubeedge:
    enabled: false
    cloudCore:
      nodeSelector: {"node-role.kubernetes.io/worker": ""}
      tolerations: []
      cloudhubPort: "10000"
      cloudhubQuicPort: "10001"
      cloudhubHttpsPort: "10002"
      cloudstreamPort: "10003"
      tunnelPort: "10004"
      cloudHub:
        advertiseAddress: 
          - ""           
        nodeLimit: "100"
      service:
        cloudhubNodePort: "30000"
        cloudhubQuicNodePort: "30001"
        cloudhubHttpsNodePort: "30002"
        cloudstreamNodePort: "30003"
        tunnelNodePort: "30004"
    edgeWatcher:
      nodeSelector: {"node-role.kubernetes.io/worker": ""}
      tolerations: []
      edgeWatcherAgent:
        nodeSelector: {"node-role.kubernetes.io/worker": ""}
        tolerations: []
```

### 3.3、开始安装

```bash
./kk create cluster -f config-sample.yaml
```

然后弹出输入`yes`，接下来耐心等待就OK。

整个安装过程可能需要 10 到 20 分钟，具体取决于您的计算机和网络环境。

## 4、验证安装

安装完成后，您会看到如下内容：

```bash
#####################################################
###              Welcome to KubeSphere!           ###
#####################################################

Console: http://192.168.0.2:30880
Account: admin
Password: P@88w0rd

NOTES：
  1. After you log into the console, please check the
     monitoring status of service components in
     the "Cluster Management". If any service is not
     ready, please wait patiently until all components
     are up and running.
  2. Please change the default password after login.

#####################################################
https://kubesphere.io             20xx-xx-xx xx:xx:xx
#####################################################
```

现在，您可以通过 `<NodeIP:30880` 使用默认帐户和密码 (`admin/P@88w0rd`) 访问 KubeSphere 的 Web 控制台。

